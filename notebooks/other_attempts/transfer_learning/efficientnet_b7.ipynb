{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF-t533iGMyw"
   },
   "source": [
    "# **Transfer Learning using EfficientNetB7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KakJ9hlKwfYJ"
   },
   "outputs": [],
   "source": [
    "#@title **Loading data from gdrive to memory**\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd /content/drive/MyDrive/ANNDL_Project\n",
    "\n",
    "%cd ../../datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwIzjeRcnS4z"
   },
   "outputs": [],
   "source": [
    "!yes A | unzip data_splitted.zip -d data_splitted\n",
    "!yes A | unzip data_cleaned_for_training.zip -d data_cleaned_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "NEvKdq6e74bY"
   },
   "outputs": [],
   "source": [
    "#@title **Imports**\n",
    "import warnings\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jSx3yOBD8w43"
   },
   "outputs": [],
   "source": [
    "#@title **Metadata and variables**\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "dir = \"data_splitted\"\n",
    "\n",
    "input_shape = (96, 96, 3)\n",
    "nclasses = 8\n",
    "num_epochs_tl = 60\n",
    "num_epochs_ft = 40\n",
    "seed = 42\n",
    "\n",
    "use_cleaned_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8qUldqliRSFG"
   },
   "outputs": [],
   "source": [
    "#@title **Setting seed and/or suppressing warnings**\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "UYNc6c2fcUkQ"
   },
   "outputs": [],
   "source": [
    "#@title **Image Dataset from directory (already resized to the shape needed by the pre-trained network)**\n",
    "def get_image_dataset(dir, seed, width=96, height=96):\n",
    "    \n",
    "    train_dir = dir+\"/train\"\n",
    "    # train_dir = \"data_cleaned_for_training\"\n",
    "    test_dir = dir+\"/test\"\n",
    "    val_dir = dir+\"/val\"\n",
    "    train_ds = tfk.utils.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        label_mode='categorical',\n",
    "        seed=seed,\n",
    "        image_size=(224,224),\n",
    "        batch_size = 32\n",
    "    )\n",
    "    val_ds = tfk.utils.image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        label_mode='categorical',\n",
    "        seed=seed,\n",
    "        image_size=(224,224),\n",
    "        batch_size = 32\n",
    "    )\n",
    "    test_ds = tfk.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        label_mode='categorical',\n",
    "        seed=seed,\n",
    "        image_size=(224,224),\n",
    "        batch_size = 32\n",
    "    )\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BPVRFVhTHr-E"
   },
   "outputs": [],
   "source": [
    "#@title **Utility function to count number of samples in a directory**\n",
    "def count_samples(directory):\n",
    "  count = 0\n",
    "  for root_dir, cur_dir, files in os.walk(directory):\n",
    "      count += len(files)\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "XX9cZU04__Aa"
   },
   "outputs": [],
   "source": [
    "#@title **Utility function to create folders and callbacks for training**\n",
    "def create_folders_and_callbacks(model_name):\n",
    "\n",
    "  exps_dir = os.path.join('trained_models/citte')\n",
    "  if not os.path.exists(exps_dir):\n",
    "      os.makedirs(exps_dir)\n",
    "\n",
    "  now = datetime.now().strftime('%m-%d_%H-%M-%S')\n",
    "\n",
    "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "  if not os.path.exists(exp_dir):\n",
    "      os.makedirs(exp_dir)\n",
    "      \n",
    "  callbacks = []\n",
    "\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "  if not os.path.exists(ckpt_dir):\n",
    "      os.makedirs(ckpt_dir)\n",
    "\n",
    "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                                     filepath=ckpt_dir + '/cp-{val_accuracy:.2f}-{epoch:02d}.ckpt', # Checkpoint is saved with validation accuracy in the filename\n",
    "                                                     monitor='val_accuracy', \n",
    "                                                     save_weights_only=True, # True to save only weights\n",
    "                                                     save_best_only=True, # True to save only the best epoch \n",
    "                                                     initial_value_threshold=0.7\n",
    "                                                     ) # Model is saved only if val_accuracy > initial_value_threshold\n",
    "\n",
    "  callbacks.append(ckpt_callback)\n",
    "\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "  if not os.path.exists(tb_dir):\n",
    "      os.makedirs(tb_dir)\n",
    "      \n",
    "  # By default shows losses and metrics for both training and validation\n",
    "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "  callbacks.append(tb_callback)\n",
    "\n",
    "  # Early Stopping\n",
    "  # --------------\n",
    "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "  callbacks.append(es_callback)\n",
    "\n",
    "  return callbacks, exp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAUxg31mGjwP"
   },
   "source": [
    "---\n",
    "\n",
    "# **Transfer Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "0QjsiattmgDk"
   },
   "outputs": [],
   "source": [
    "#@title **Getting class weights to handle classes' sample imbalance**\n",
    "def get_class_weights():\n",
    "\n",
    "  num_images = count_samples(dir)\n",
    "  elements = np.zeros(nclasses)\n",
    "  weights = np.zeros(nclasses)\n",
    "\n",
    "  for i in range(nclasses):\n",
    "      elements[i] = count_samples(\"data_cleaned_for_training/Species\"+str(i+1))\n",
    "      weights[i] = (1 / elements[i]) * (num_images / float(nclasses))\n",
    "      \n",
    "  class_weight = {0: weights[0], 1: weights[1], 2: weights[2], 3: weights[3], 4: weights[4], 5: weights[5], 6: weights[6], 7: weights[7]}\n",
    "  print(\"Samples count: \", elements)\n",
    "  print(\"Class weights: \", weights)\n",
    "\n",
    "  return class_weight\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "d9mVtFPOST9R"
   },
   "outputs": [],
   "source": [
    "#@title **External Augmentation block**\n",
    "\n",
    "img_augmentation = Sequential(\n",
    "    [\n",
    "        tfk.layers.RandomRotation(factor=1),\n",
    "        tfk.layers.RandomZoom(width_factor=0.2, height_factor=0.2),\n",
    "        tfk.layers.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "        tfk.layers.RandomFlip(),\n",
    "        tfk.layers.RandomContrast(factor=0.3),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMKW4Q_GMoCw"
   },
   "outputs": [],
   "source": [
    "#@title **1. Transfer Learning using pre-trained EfficientNetB7 and external augmentation**\n",
    "\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "def build_EfficientNetB7():\n",
    "    inputs = tfkl.Input(shape=(224, 224, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    # preprocessing of images needed by this type of pretrained network\n",
    "    x = preprocess_input(x)\n",
    "    model = tfk.applications.EfficientNetB7(\n",
    "          include_top=False, \n",
    "          input_tensor=x, \n",
    "          weights=\"imagenet\", \n",
    "          input_shape=(224, 224, 3)\n",
    "        )\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = tfkl.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    top_dropout_rate = 0.3\n",
    "    x = tfkl.Dropout(top_dropout_rate, name=\"dense_dropout\")(x)\n",
    "    x = tfkl.Dense(1024, activation=\"relu\", name=\"dense\")(x)\n",
    "    x = tfkl.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = tfkl.Dense(8, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tl_model = build_EfficientNetB7()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRe5tpQk5cCV"
   },
   "outputs": [],
   "source": [
    "tl_model.summary(\n",
    "    expand_nested=True,\n",
    "    show_trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Z3M9ylFUYzmv"
   },
   "outputs": [],
   "source": [
    "#@title Transfer Learning training phase (with ImageDataGenerators)\n",
    "\n",
    "callbacks, model_folder_dir = create_folders_and_callbacks(model_name='EfficientNetB7_TL_CB')\n",
    "\n",
    "train_gen, valid_gen, test_gen = get_image_dataset(dir=dir, seed=seed)\n",
    "\n",
    "tl_history = tl_model.fit(\n",
    "    x = train_gen,\n",
    "    batch_size = 64,\n",
    "    epochs = num_epochs_tl,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = valid_gen,\n",
    "    class_weight = get_class_weights()\n",
    "    ).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaKxRgp-HQzG"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfPJePumjRjp"
   },
   "outputs": [],
   "source": [
    "#@title Reloading the model after Transfer Learning (through checkpoints or the entire model)\n",
    "\n",
    "# ft_model = tfk.models.load_model('saved_models/XLarge_last_possibility')\n",
    "\n",
    "ft_model = build_EfficientNetB7()\n",
    "ft_model.load_weights(\"trained_models/...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EsdkQDocW-z"
   },
   "outputs": [],
   "source": [
    "ft_model.summary(\n",
    "    expand_nested=True,\n",
    "    show_trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zjBB3hO_OSI"
   },
   "outputs": [],
   "source": [
    "#@title **Unfreezing completely (or part of) the pretrained network and re-compiling**\n",
    "\n",
    "\n",
    "# It is also possible to partially unfreeze the pretrained network:\n",
    "\n",
    "layers_to_unfreeze = len(ft_model.layers)\n",
    "for i, layer in enumerate(ft_model.layers[-layers_to_unfreeze:]):\n",
    "    # BatchNormalization layers are not unfreezed because, if trainable, they lead to a performance decrease\n",
    "    if not isinstance(layer, tfk.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# ft_model.get_layer('efficientnet_b7').trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z_hgZuNkCIP"
   },
   "outputs": [],
   "source": [
    "ft_model.summary(\n",
    "    expand_nested=True,\n",
    "    show_trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqtC-Cddi251"
   },
   "outputs": [],
   "source": [
    "#@title Re-compile the model to apply changes\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gReRof3iferf"
   },
   "outputs": [],
   "source": [
    "#@title **Fine-Tuning the partially unfreezed model**\n",
    "\n",
    "callbacks, model_folder_dir = create_folders_and_callbacks(model_name='EfficientNetB7_FT_CB')\n",
    "\n",
    "train_gen, valid_gen, test_gen = get_image_dataset(dir=dir, seed=seed)\n",
    "\n",
    "ft_history = ft_model.fit(\n",
    "    x = train_gen,\n",
    "    batch_size = 64,\n",
    "    epochs = num_epochs_ft,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = valid_gen,\n",
    "    class_weight = get_class_weights()\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA1PZYFxSyDO"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "# **Save of models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5UfFNLhS4g6"
   },
   "outputs": [],
   "source": [
    "model.save(\"saved_models/...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NSKgzvoLBQT"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "# **Loading of models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltJzWhgvuYSw"
   },
   "outputs": [],
   "source": [
    "#@title **Loading of an existing model (having only the weights)**\n",
    "ft_model = build_EfficientNetB7()\n",
    "ft_model.load_weights('saved_models/...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EMAei7BR-te"
   },
   "outputs": [],
   "source": [
    "#@title **Loading of an existing model (Complete)**\n",
    "model = tf.keras.models.load_model(\"saved_models/...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWQhfwtmSShW"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# **Model testing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_Slc1rrspXF"
   },
   "outputs": [],
   "source": [
    "#@title **Testing a model and re-saving**\n",
    "\n",
    "train_gen, valid_gen, test_gen = get_image_dataset(dir=dir, seed=seed)\n",
    "model_test_metrics = ft_model.evaluate(test_gen, return_dict=True)\n",
    "\n",
    "# saving model in saved_models/modelname_accuracy\n",
    "saved_model_name = 'EfficientNetB7_' + str(model_test_metrics[\"accuracy\"])\n",
    "saved_model_dir = 'saved_models/' + saved_model_name\n",
    "ft_model.save(saved_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUHrx4B3SYko"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# **Download of the model in .zip format**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO7CjPfa_gSJ"
   },
   "outputs": [],
   "source": [
    "zipped_model = saved_model_dir + '/' + saved_model_name + '.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwoOlqg7_vAT"
   },
   "outputs": [],
   "source": [
    "!zip -r {zipped_model} {saved_model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuP0QlFQ_zSm"
   },
   "outputs": [],
   "source": [
    "files.download(zipped_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mckeoLzeOAvx"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "OaKxRgp-HQzG"
   ],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}