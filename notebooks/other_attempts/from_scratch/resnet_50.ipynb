{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF-t533iGMyw"
   },
   "source": [
    "# **ResNet 50 from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KakJ9hlKwfYJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6688ff37-1f01-4604-eca4-c193c161ba63"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/.shortcut-targets-by-id/15O-hdeXPBICW_RJDpxFM_YoVERTpVMjK/ANNDL_Project\n"
     ]
    }
   ],
   "source": [
    "#@title **Loading data from gdrive to memory**\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd /content/drive/MyDrive/ANNDL_Project\n",
    "\n",
    "%cd ../../datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwIzjeRcnS4z"
   },
   "outputs": [],
   "source": [
    "!yes A | unzip data_splitted.zip -d data_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEvKdq6e74bY"
   },
   "outputs": [],
   "source": [
    "#@title **Imports**\n",
    "import warnings\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSx3yOBD8w43"
   },
   "outputs": [],
   "source": [
    "#@title **Metadata and variables**\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "dir = \"data_splitted\"\n",
    "\n",
    "input_shape = (96, 96, 3)\n",
    "nclasses = 8\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qUldqliRSFG",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title **Setting seed and/or suppressing warnings**\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYNl5biYRnAT"
   },
   "outputs": [],
   "source": [
    "#@title **Method that returns ImageDataGenerators (iterators) of augmented images**\n",
    "def get_dataset_generator(dir):\n",
    "      \n",
    "    train_dir = dir + \"/train\"\n",
    "    test_dir = dir + \"/test\"\n",
    "    val_dir = dir + \"/val\"\n",
    "\n",
    "\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=15,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        fill_mode='reflect',\n",
    "                                        )\n",
    "\n",
    "    valid_data_gen = ImageDataGenerator(\n",
    "        # rescale=1 / 255.\n",
    "        )\n",
    "    test_data_gen = ImageDataGenerator(\n",
    "        # rescale=1 / 255.\n",
    "        )\n",
    "\n",
    "    train_gen = train_data_gen.flow_from_directory(directory=train_dir,\n",
    "                                                           target_size=(input_shape[0], input_shape[1]),\n",
    "                                                           color_mode='rgb',\n",
    "                                                           class_mode='categorical',\n",
    "                                                           batch_size=64,\n",
    "                                                           shuffle=True)\n",
    "    valid_gen = valid_data_gen.flow_from_directory(directory=val_dir,\n",
    "                                                   target_size=(input_shape[0], input_shape[1]),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   class_mode='categorical',\n",
    "                                                   batch_size=64,\n",
    "                                                   shuffle=True)\n",
    "    test_gen = test_data_gen.flow_from_directory(directory=test_dir,\n",
    "                                                 target_size=(input_shape[0], input_shape[1]),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=64,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "    return train_gen, valid_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XX9cZU04__Aa"
   },
   "outputs": [],
   "source": [
    "#@title **Utility function to create folders and callbacks for training**\n",
    "def create_folders_and_callbacks(model_name):\n",
    "\n",
    "  exps_dir = os.path.join('trained_models/citte')\n",
    "  if not os.path.exists(exps_dir):\n",
    "      os.makedirs(exps_dir)\n",
    "\n",
    "  now = datetime.now().strftime('%m-%d_%H-%M-%S')\n",
    "\n",
    "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "  if not os.path.exists(exp_dir):\n",
    "      os.makedirs(exp_dir)\n",
    "      \n",
    "  callbacks = []\n",
    "\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "  if not os.path.exists(ckpt_dir):\n",
    "      os.makedirs(ckpt_dir)\n",
    "\n",
    "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_dir + '/cp-{val_accuracy:.2f}-{epoch:02d}.ckpt', # Checkpoint is saved with validation accuracy in the filename\n",
    "                                                     monitor='val_accuracy', \n",
    "                                                     save_weights_only=True, # True to save only weights\n",
    "                                                     save_best_only=True, # True to save only the best epoch \n",
    "                                                     initial_value_threshold=0.7\n",
    "                                                     ) # Model is saved only if val_accuracy > initial_value_threshold\n",
    "\n",
    "  callbacks.append(ckpt_callback)\n",
    "\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "  if not os.path.exists(tb_dir):\n",
    "      os.makedirs(tb_dir)\n",
    "      \n",
    "  # By default shows losses and metrics for both training and validation\n",
    "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "  callbacks.append(tb_callback)\n",
    "\n",
    "  # Early Stopping\n",
    "  # --------------\n",
    "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "  callbacks.append(es_callback)\n",
    "\n",
    "  return callbacks, exp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUkNtG-LAOXk"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **Models from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40q47UVe-LkF"
   },
   "outputs": [],
   "source": [
    "#@title **2. ResNet-50**\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "        \n",
    "    X = tfkl.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "        \n",
    "    X = tfkl.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "\n",
    "    X = tfkl.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Add shortcut value to main path\n",
    "    X = tfkl.Add()([X_shortcut, X])\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "        \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = tfkl.Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "    X = tfkl.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "    X = tfkl.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    X_shortcut = tfkl.Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = tfkl.BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "    X = tfkl.Add()([X_shortcut, X])\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "   \n",
    "    return X\n",
    "\n",
    "def original_ResNet50(input_shape = (96, 96, 3), classes = 8):\n",
    "    X_input = tfkl.Input(input_shape)\n",
    "    X = tfkl.ZeroPadding2D((3, 3))(X_input)\n",
    "    X = tfkl.Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "    X = tfkl.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    X = tfkl.AveragePooling2D(pool_size=(2, 2),name='avg_pool')(X)\n",
    "    X = tfkl.Flatten()(X)\n",
    "    X = tfkl.Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    return model\n",
    "\n",
    "def build_ResNet50(input_shape = (96, 96, 3), nclasses = 8):\n",
    "    X_input = tfkl.Input(input_shape)\n",
    "    X = tfkl.ZeroPadding2D((3, 3))(X_input)\n",
    "    X = tfkl.Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfkl.BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = tfkl.Activation('relu')(X)\n",
    "    X = tfkl.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    X = tfkl.AveragePooling2D(pool_size=(2, 2),name='avg_pool')(X)\n",
    "    X = tfkl.Flatten()(X)\n",
    "    X = tfkl.Dropout(0.2, seed=seed)(X)\n",
    "    X = tfkl.Dense(units=32, name='Classifier1', kernel_initializer=tfk.initializers.HeUniform(seed),\n",
    "                                    activation='relu')(X)\n",
    "    X = tfkl.Dense(nclasses, activation='softmax', name='fc' + str(nclasses), kernel_initializer = glorot_uniform(seed))(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "    return model    \n",
    "\n",
    "model = build_ResNet50(input_shape, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary(expand_nested=True)"
   ],
   "metadata": {
    "id": "Q77P0wAhi4dW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "050a25b5-88bb-46a5-97e7-473325b7bdbb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 102, 102, 3)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 48, 48, 64)   9472        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNormalization)  (None, 48, 48, 64)   256         ['conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 48, 48, 64)   0           ['bn_conv1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 23, 23, 64)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " res2a_branch2a (Conv2D)        (None, 23, 23, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " bn2a_branch2a (BatchNormalizat  (None, 23, 23, 64)  256         ['res2a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 23, 23, 64)   0           ['bn2a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2b (Conv2D)        (None, 23, 23, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " bn2a_branch2b (BatchNormalizat  (None, 23, 23, 64)  256         ['res2a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 23, 23, 64)   0           ['bn2a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch1 (Conv2D)         (None, 23, 23, 256)  16640       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " res2a_branch2c (Conv2D)        (None, 23, 23, 256)  16640       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " bn2a_branch1 (BatchNormalizati  (None, 23, 23, 256)  1024       ['res2a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " bn2a_branch2c (BatchNormalizat  (None, 23, 23, 256)  1024       ['res2a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 23, 23, 256)  0           ['bn2a_branch1[0][0]',           \n",
      "                                                                  'bn2a_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 23, 23, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " res2b_branch2a (Conv2D)        (None, 23, 23, 64)   16448       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2a (BatchNormalizat  (None, 23, 23, 64)  256         ['res2b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 23, 23, 64)   0           ['bn2b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2b_branch2b (Conv2D)        (None, 23, 23, 64)   36928       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2b (BatchNormalizat  (None, 23, 23, 64)  256         ['res2b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 23, 23, 64)   0           ['bn2b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2b_branch2c (Conv2D)        (None, 23, 23, 256)  16640       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " bn2b_branch2c (BatchNormalizat  (None, 23, 23, 256)  1024       ['res2b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 23, 23, 256)  0           ['activation_3[0][0]',           \n",
      "                                                                  'bn2b_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 23, 23, 256)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " res2c_branch2a (Conv2D)        (None, 23, 23, 64)   16448       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " bn2c_branch2a (BatchNormalizat  (None, 23, 23, 64)  256         ['res2c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 23, 23, 64)   0           ['bn2c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res2c_branch2b (Conv2D)        (None, 23, 23, 64)   36928       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " bn2c_branch2b (BatchNormalizat  (None, 23, 23, 64)  256         ['res2c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 23, 23, 64)   0           ['bn2c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res2c_branch2c (Conv2D)        (None, 23, 23, 256)  16640       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " bn2c_branch2c (BatchNormalizat  (None, 23, 23, 256)  1024       ['res2c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 23, 23, 256)  0           ['activation_6[0][0]',           \n",
      "                                                                  'bn2c_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 23, 23, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " res3a_branch2a (Conv2D)        (None, 12, 12, 128)  32896       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " bn3a_branch2a (BatchNormalizat  (None, 12, 12, 128)  512        ['res3a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 12, 12, 128)  0           ['bn3a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch2b (Conv2D)        (None, 12, 12, 128)  147584      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch2b (BatchNormalizat  (None, 12, 12, 128)  512        ['res3a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 12, 12, 128)  0           ['bn3a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3a_branch1 (Conv2D)         (None, 12, 12, 512)  131584      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " res3a_branch2c (Conv2D)        (None, 12, 12, 512)  66048       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " bn3a_branch1 (BatchNormalizati  (None, 12, 12, 512)  2048       ['res3a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " bn3a_branch2c (BatchNormalizat  (None, 12, 12, 512)  2048       ['res3a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 12, 12, 512)  0           ['bn3a_branch1[0][0]',           \n",
      "                                                                  'bn3a_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 12, 12, 512)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " res3b_branch2a (Conv2D)        (None, 12, 12, 128)  65664       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " bn3b_branch2a (BatchNormalizat  (None, 12, 12, 128)  512        ['res3b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 12, 12, 128)  0           ['bn3b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3b_branch2b (Conv2D)        (None, 12, 12, 128)  147584      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " bn3b_branch2b (BatchNormalizat  (None, 12, 12, 128)  512        ['res3b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 12, 12, 128)  0           ['bn3b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3b_branch2c (Conv2D)        (None, 12, 12, 512)  66048       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " bn3b_branch2c (BatchNormalizat  (None, 12, 12, 512)  2048       ['res3b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 12, 12, 512)  0           ['activation_12[0][0]',          \n",
      "                                                                  'bn3b_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 12, 12, 512)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " res3c_branch2a (Conv2D)        (None, 12, 12, 128)  65664       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " bn3c_branch2a (BatchNormalizat  (None, 12, 12, 128)  512        ['res3c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 12, 12, 128)  0           ['bn3c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3c_branch2b (Conv2D)        (None, 12, 12, 128)  147584      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " bn3c_branch2b (BatchNormalizat  (None, 12, 12, 128)  512        ['res3c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 12, 12, 128)  0           ['bn3c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3c_branch2c (Conv2D)        (None, 12, 12, 512)  66048       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " bn3c_branch2c (BatchNormalizat  (None, 12, 12, 512)  2048       ['res3c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 12, 12, 512)  0           ['activation_15[0][0]',          \n",
      "                                                                  'bn3c_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 12, 12, 512)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " res3d_branch2a (Conv2D)        (None, 12, 12, 128)  65664       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " bn3d_branch2a (BatchNormalizat  (None, 12, 12, 128)  512        ['res3d_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 12, 12, 128)  0           ['bn3d_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res3d_branch2b (Conv2D)        (None, 12, 12, 128)  147584      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " bn3d_branch2b (BatchNormalizat  (None, 12, 12, 128)  512        ['res3d_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 12, 12, 128)  0           ['bn3d_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res3d_branch2c (Conv2D)        (None, 12, 12, 512)  66048       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " bn3d_branch2c (BatchNormalizat  (None, 12, 12, 512)  2048       ['res3d_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 12, 12, 512)  0           ['activation_18[0][0]',          \n",
      "                                                                  'bn3d_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 12, 12, 512)  0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " res4a_branch2a (Conv2D)        (None, 6, 6, 256)    131328      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2a (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 6, 6, 256)    0           ['bn4a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2b (Conv2D)        (None, 6, 6, 256)    590080      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch2b (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 6, 6, 256)    0           ['bn4a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch1 (Conv2D)         (None, 6, 6, 1024)   525312      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " res4a_branch2c (Conv2D)        (None, 6, 6, 1024)   263168      ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " bn4a_branch1 (BatchNormalizati  (None, 6, 6, 1024)  4096        ['res4a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " bn4a_branch2c (BatchNormalizat  (None, 6, 6, 1024)  4096        ['res4a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 6, 6, 1024)   0           ['bn4a_branch1[0][0]',           \n",
      "                                                                  'bn4a_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 6, 6, 1024)   0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " res4b_branch2a (Conv2D)        (None, 6, 6, 256)    262400      ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " bn4b_branch2a (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 6, 6, 256)    0           ['bn4b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4b_branch2b (Conv2D)        (None, 6, 6, 256)    590080      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " bn4b_branch2b (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 6, 6, 256)    0           ['bn4b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4b_branch2c (Conv2D)        (None, 6, 6, 1024)   263168      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " bn4b_branch2c (BatchNormalizat  (None, 6, 6, 1024)  4096        ['res4b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 6, 6, 1024)   0           ['activation_24[0][0]',          \n",
      "                                                                  'bn4b_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 6, 6, 1024)   0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " res4c_branch2a (Conv2D)        (None, 6, 6, 256)    262400      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " bn4c_branch2a (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 6, 6, 256)    0           ['bn4c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4c_branch2b (Conv2D)        (None, 6, 6, 256)    590080      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " bn4c_branch2b (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 6, 6, 256)    0           ['bn4c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4c_branch2c (Conv2D)        (None, 6, 6, 1024)   263168      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " bn4c_branch2c (BatchNormalizat  (None, 6, 6, 1024)  4096        ['res4c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 6, 1024)   0           ['activation_27[0][0]',          \n",
      "                                                                  'bn4c_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 6, 6, 1024)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " res4d_branch2a (Conv2D)        (None, 6, 6, 256)    262400      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " bn4d_branch2a (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4d_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 6, 6, 256)    0           ['bn4d_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4d_branch2b (Conv2D)        (None, 6, 6, 256)    590080      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " bn4d_branch2b (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4d_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 6, 6, 256)    0           ['bn4d_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4d_branch2c (Conv2D)        (None, 6, 6, 1024)   263168      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " bn4d_branch2c (BatchNormalizat  (None, 6, 6, 1024)  4096        ['res4d_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 6, 6, 1024)   0           ['activation_30[0][0]',          \n",
      "                                                                  'bn4d_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 6, 6, 1024)   0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " res4e_branch2a (Conv2D)        (None, 6, 6, 256)    262400      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " bn4e_branch2a (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4e_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 6, 6, 256)    0           ['bn4e_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4e_branch2b (Conv2D)        (None, 6, 6, 256)    590080      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " bn4e_branch2b (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4e_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 6, 6, 256)    0           ['bn4e_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4e_branch2c (Conv2D)        (None, 6, 6, 1024)   263168      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " bn4e_branch2c (BatchNormalizat  (None, 6, 6, 1024)  4096        ['res4e_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 6, 6, 1024)   0           ['activation_33[0][0]',          \n",
      "                                                                  'bn4e_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 6, 6, 1024)   0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " res4f_branch2a (Conv2D)        (None, 6, 6, 256)    262400      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " bn4f_branch2a (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4f_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 6, 6, 256)    0           ['bn4f_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res4f_branch2b (Conv2D)        (None, 6, 6, 256)    590080      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " bn4f_branch2b (BatchNormalizat  (None, 6, 6, 256)   1024        ['res4f_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 6, 6, 256)    0           ['bn4f_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res4f_branch2c (Conv2D)        (None, 6, 6, 1024)   263168      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " bn4f_branch2c (BatchNormalizat  (None, 6, 6, 1024)  4096        ['res4f_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 6, 6, 1024)   0           ['activation_36[0][0]',          \n",
      "                                                                  'bn4f_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 6, 6, 1024)   0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " res5a_branch2a (Conv2D)        (None, 3, 3, 512)    524800      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2a (BatchNormalizat  (None, 3, 3, 512)   2048        ['res5a_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 3, 3, 512)    0           ['bn5a_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2b (Conv2D)        (None, 3, 3, 512)    2359808     ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch2b (BatchNormalizat  (None, 3, 3, 512)   2048        ['res5a_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 3, 3, 512)    0           ['bn5a_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch1 (Conv2D)         (None, 3, 3, 2048)   2099200     ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " res5a_branch2c (Conv2D)        (None, 3, 3, 2048)   1050624     ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " bn5a_branch1 (BatchNormalizati  (None, 3, 3, 2048)  8192        ['res5a_branch1[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " bn5a_branch2c (BatchNormalizat  (None, 3, 3, 2048)  8192        ['res5a_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 3, 3, 2048)   0           ['bn5a_branch1[0][0]',           \n",
      "                                                                  'bn5a_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 3, 3, 2048)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " res5b_branch2a (Conv2D)        (None, 3, 3, 512)    1049088     ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " bn5b_branch2a (BatchNormalizat  (None, 3, 3, 512)   2048        ['res5b_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 3, 3, 512)    0           ['bn5b_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5b_branch2b (Conv2D)        (None, 3, 3, 512)    2359808     ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " bn5b_branch2b (BatchNormalizat  (None, 3, 3, 512)   2048        ['res5b_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 3, 3, 512)    0           ['bn5b_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5b_branch2c (Conv2D)        (None, 3, 3, 2048)   1050624     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " bn5b_branch2c (BatchNormalizat  (None, 3, 3, 2048)  8192        ['res5b_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 3, 3, 2048)   0           ['activation_42[0][0]',          \n",
      "                                                                  'bn5b_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 3, 3, 2048)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " res5c_branch2a (Conv2D)        (None, 3, 3, 512)    1049088     ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " bn5c_branch2a (BatchNormalizat  (None, 3, 3, 512)   2048        ['res5c_branch2a[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 3, 3, 512)    0           ['bn5c_branch2a[0][0]']          \n",
      "                                                                                                  \n",
      " res5c_branch2b (Conv2D)        (None, 3, 3, 512)    2359808     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " bn5c_branch2b (BatchNormalizat  (None, 3, 3, 512)   2048        ['res5c_branch2b[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 3, 3, 512)    0           ['bn5c_branch2b[0][0]']          \n",
      "                                                                                                  \n",
      " res5c_branch2c (Conv2D)        (None, 3, 3, 2048)   1050624     ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " bn5c_branch2c (BatchNormalizat  (None, 3, 3, 2048)  8192        ['res5c_branch2c[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 3, 3, 2048)   0           ['activation_45[0][0]',          \n",
      "                                                                  'bn5c_branch2c[0][0]']          \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 3, 3, 2048)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D)    (None, 1, 1, 2048)   0           ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " Classifier1 (Dense)            (None, 32)           65568       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " fc8 (Dense)                    (None, 8)            264         ['Classifier1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,653,544\n",
      "Trainable params: 23,600,424\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSa4xcuaDMfJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b47d364f-709a-4c67-aee2-c2f6f285857a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2475 images belonging to 8 classes.\n",
      "Found 527 images belonging to 8 classes.\n",
      "Found 540 images belonging to 8 classes.\n",
      "Epoch 1/250\n",
      "78/78 [==============================] - 16s 147ms/step - loss: 2.2223 - accuracy: 0.1911 - val_loss: 2.0523 - val_accuracy: 0.1461\n",
      "Epoch 2/250\n",
      "78/78 [==============================] - 12s 157ms/step - loss: 1.7665 - accuracy: 0.3301 - val_loss: 2.4272 - val_accuracy: 0.1461\n",
      "Epoch 3/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.6525 - accuracy: 0.3782 - val_loss: 3.1443 - val_accuracy: 0.1518\n",
      "Epoch 4/250\n",
      "78/78 [==============================] - 11s 141ms/step - loss: 1.5601 - accuracy: 0.4117 - val_loss: 4.0207 - val_accuracy: 0.1518\n",
      "Epoch 5/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 1.4926 - accuracy: 0.4356 - val_loss: 2.6041 - val_accuracy: 0.2068\n",
      "Epoch 6/250\n",
      "78/78 [==============================] - 11s 138ms/step - loss: 1.4566 - accuracy: 0.4533 - val_loss: 1.4678 - val_accuracy: 0.4535\n",
      "Epoch 7/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.4206 - accuracy: 0.4655 - val_loss: 1.5009 - val_accuracy: 0.4573\n",
      "Epoch 8/250\n",
      "78/78 [==============================] - 12s 148ms/step - loss: 1.3893 - accuracy: 0.4780 - val_loss: 1.7568 - val_accuracy: 0.4023\n",
      "Epoch 9/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.4120 - accuracy: 0.4719 - val_loss: 1.8029 - val_accuracy: 0.3814\n",
      "Epoch 10/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.3507 - accuracy: 0.4913 - val_loss: 2.3058 - val_accuracy: 0.2808\n",
      "Epoch 11/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.3310 - accuracy: 0.5139 - val_loss: 1.8331 - val_accuracy: 0.3909\n",
      "Epoch 12/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.3421 - accuracy: 0.5055 - val_loss: 1.9854 - val_accuracy: 0.3510\n",
      "Epoch 13/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 1.2826 - accuracy: 0.5374 - val_loss: 1.9105 - val_accuracy: 0.3814\n",
      "Epoch 14/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.2777 - accuracy: 0.5321 - val_loss: 2.1946 - val_accuracy: 0.2562\n",
      "Epoch 15/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.2625 - accuracy: 0.5398 - val_loss: 1.9950 - val_accuracy: 0.3435\n",
      "Epoch 16/250\n",
      "78/78 [==============================] - 11s 138ms/step - loss: 1.2276 - accuracy: 0.5560 - val_loss: 2.0312 - val_accuracy: 0.4099\n",
      "Epoch 17/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 1.2751 - accuracy: 0.5430 - val_loss: 1.7411 - val_accuracy: 0.3700\n",
      "Epoch 18/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 1.2163 - accuracy: 0.5685 - val_loss: 1.4310 - val_accuracy: 0.4877\n",
      "Epoch 19/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.1979 - accuracy: 0.5677 - val_loss: 2.6858 - val_accuracy: 0.3245\n",
      "Epoch 20/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 1.1937 - accuracy: 0.5802 - val_loss: 4.5631 - val_accuracy: 0.2922\n",
      "Epoch 21/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.1660 - accuracy: 0.5883 - val_loss: 2.5992 - val_accuracy: 0.3340\n",
      "Epoch 22/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 1.1612 - accuracy: 0.5851 - val_loss: 2.2313 - val_accuracy: 0.3036\n",
      "Epoch 23/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.1598 - accuracy: 0.5834 - val_loss: 3.0120 - val_accuracy: 0.2296\n",
      "Epoch 24/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.1202 - accuracy: 0.6040 - val_loss: 2.1765 - val_accuracy: 0.3283\n",
      "Epoch 25/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 1.1189 - accuracy: 0.6113 - val_loss: 1.9816 - val_accuracy: 0.4175\n",
      "Epoch 26/250\n",
      "78/78 [==============================] - 12s 150ms/step - loss: 1.0800 - accuracy: 0.6109 - val_loss: 1.8188 - val_accuracy: 0.3548\n",
      "Epoch 27/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 1.0814 - accuracy: 0.6166 - val_loss: 2.2253 - val_accuracy: 0.3757\n",
      "Epoch 28/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 1.0963 - accuracy: 0.6048 - val_loss: 1.9217 - val_accuracy: 0.3624\n",
      "Epoch 29/250\n",
      "78/78 [==============================] - 10s 135ms/step - loss: 1.0806 - accuracy: 0.6154 - val_loss: 1.5591 - val_accuracy: 0.4763\n",
      "Epoch 30/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.0700 - accuracy: 0.6158 - val_loss: 2.8895 - val_accuracy: 0.2372\n",
      "Epoch 31/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.0694 - accuracy: 0.6259 - val_loss: 1.7119 - val_accuracy: 0.4535\n",
      "Epoch 32/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 1.0442 - accuracy: 0.6242 - val_loss: 2.1367 - val_accuracy: 0.3719\n",
      "Epoch 33/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 1.0397 - accuracy: 0.6275 - val_loss: 1.7134 - val_accuracy: 0.4440\n",
      "Epoch 34/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 1.0109 - accuracy: 0.6360 - val_loss: 2.2123 - val_accuracy: 0.3719\n",
      "Epoch 35/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 1.0045 - accuracy: 0.6412 - val_loss: 1.0917 - val_accuracy: 0.6129\n",
      "Epoch 36/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 1.0034 - accuracy: 0.6509 - val_loss: 2.0831 - val_accuracy: 0.3738\n",
      "Epoch 37/250\n",
      "78/78 [==============================] - 11s 138ms/step - loss: 1.0207 - accuracy: 0.6428 - val_loss: 2.3145 - val_accuracy: 0.3681\n",
      "Epoch 38/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.9923 - accuracy: 0.6485 - val_loss: 3.0325 - val_accuracy: 0.2960\n",
      "Epoch 39/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.9912 - accuracy: 0.6461 - val_loss: 2.4997 - val_accuracy: 0.2732\n",
      "Epoch 40/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.9666 - accuracy: 0.6630 - val_loss: 2.2325 - val_accuracy: 0.4175\n",
      "Epoch 41/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.9425 - accuracy: 0.6651 - val_loss: 2.1190 - val_accuracy: 0.3150\n",
      "Epoch 42/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.9597 - accuracy: 0.6655 - val_loss: 1.3868 - val_accuracy: 0.4839\n",
      "Epoch 43/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.9443 - accuracy: 0.6723 - val_loss: 1.7761 - val_accuracy: 0.4763\n",
      "Epoch 44/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.9230 - accuracy: 0.6840 - val_loss: 3.4076 - val_accuracy: 0.2600\n",
      "Epoch 45/250\n",
      "78/78 [==============================] - 12s 152ms/step - loss: 0.9276 - accuracy: 0.6719 - val_loss: 2.2185 - val_accuracy: 0.4687\n",
      "Epoch 46/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.9120 - accuracy: 0.6808 - val_loss: 1.7856 - val_accuracy: 0.4440\n",
      "Epoch 47/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.9095 - accuracy: 0.6723 - val_loss: 1.7507 - val_accuracy: 0.4744\n",
      "Epoch 48/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8905 - accuracy: 0.6848 - val_loss: 3.3256 - val_accuracy: 0.3378\n",
      "Epoch 49/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.9062 - accuracy: 0.6776 - val_loss: 5.4286 - val_accuracy: 0.2676\n",
      "Epoch 50/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.8908 - accuracy: 0.6937 - val_loss: 2.5771 - val_accuracy: 0.3909\n",
      "Epoch 51/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.8999 - accuracy: 0.6836 - val_loss: 1.8894 - val_accuracy: 0.4592\n",
      "Epoch 52/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.8929 - accuracy: 0.6881 - val_loss: 4.0003 - val_accuracy: 0.2581\n",
      "Epoch 53/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.8982 - accuracy: 0.6929 - val_loss: 2.6504 - val_accuracy: 0.3093\n",
      "Epoch 54/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.8878 - accuracy: 0.6857 - val_loss: 1.7984 - val_accuracy: 0.4383\n",
      "Epoch 55/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.8658 - accuracy: 0.7055 - val_loss: 1.1856 - val_accuracy: 0.5958\n",
      "Epoch 56/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.8935 - accuracy: 0.6853 - val_loss: 2.1231 - val_accuracy: 0.4288\n",
      "Epoch 57/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8991 - accuracy: 0.6808 - val_loss: 2.3032 - val_accuracy: 0.4156\n",
      "Epoch 58/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8573 - accuracy: 0.7038 - val_loss: 2.2605 - val_accuracy: 0.3567\n",
      "Epoch 59/250\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.8402 - accuracy: 0.7111 - val_loss: 0.9866 - val_accuracy: 0.6660\n",
      "Epoch 60/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8217 - accuracy: 0.7075 - val_loss: 2.9351 - val_accuracy: 0.3510\n",
      "Epoch 61/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8170 - accuracy: 0.7168 - val_loss: 1.6000 - val_accuracy: 0.4858\n",
      "Epoch 62/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8397 - accuracy: 0.7115 - val_loss: 2.3863 - val_accuracy: 0.3378\n",
      "Epoch 63/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8104 - accuracy: 0.7079 - val_loss: 2.7968 - val_accuracy: 0.3738\n",
      "Epoch 64/250\n",
      "78/78 [==============================] - 12s 151ms/step - loss: 0.7854 - accuracy: 0.7204 - val_loss: 2.0585 - val_accuracy: 0.4953\n",
      "Epoch 65/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.8192 - accuracy: 0.7127 - val_loss: 2.9359 - val_accuracy: 0.3302\n",
      "Epoch 66/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.7944 - accuracy: 0.7204 - val_loss: 4.0443 - val_accuracy: 0.2694\n",
      "Epoch 67/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8121 - accuracy: 0.7095 - val_loss: 2.1294 - val_accuracy: 0.3985\n",
      "Epoch 68/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.8277 - accuracy: 0.6966 - val_loss: 1.8140 - val_accuracy: 0.4231\n",
      "Epoch 69/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.7739 - accuracy: 0.7164 - val_loss: 1.6606 - val_accuracy: 0.5313\n",
      "Epoch 70/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.7585 - accuracy: 0.7370 - val_loss: 1.5993 - val_accuracy: 0.5370\n",
      "Epoch 71/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.7540 - accuracy: 0.7317 - val_loss: 2.9372 - val_accuracy: 0.3833\n",
      "Epoch 72/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.7556 - accuracy: 0.7317 - val_loss: 2.3256 - val_accuracy: 0.4383\n",
      "Epoch 73/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.7626 - accuracy: 0.7317 - val_loss: 2.8995 - val_accuracy: 0.3567\n",
      "Epoch 74/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.7544 - accuracy: 0.7354 - val_loss: 1.9263 - val_accuracy: 0.4440\n",
      "Epoch 75/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.7626 - accuracy: 0.7309 - val_loss: 1.1646 - val_accuracy: 0.6338\n",
      "Epoch 76/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.7168 - accuracy: 0.7451 - val_loss: 1.8405 - val_accuracy: 0.4744\n",
      "Epoch 77/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.7351 - accuracy: 0.7455 - val_loss: 3.7721 - val_accuracy: 0.3605\n",
      "Epoch 78/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.7114 - accuracy: 0.7495 - val_loss: 2.5443 - val_accuracy: 0.3776\n",
      "Epoch 79/250\n",
      "78/78 [==============================] - 10s 133ms/step - loss: 0.7481 - accuracy: 0.7414 - val_loss: 2.5464 - val_accuracy: 0.3738\n",
      "Epoch 80/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.6839 - accuracy: 0.7669 - val_loss: 1.8835 - val_accuracy: 0.5161\n",
      "Epoch 81/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.7161 - accuracy: 0.7410 - val_loss: 1.4878 - val_accuracy: 0.5693\n",
      "Epoch 82/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.7215 - accuracy: 0.7438 - val_loss: 2.9262 - val_accuracy: 0.3643\n",
      "Epoch 83/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.7221 - accuracy: 0.7491 - val_loss: 1.3933 - val_accuracy: 0.5389\n",
      "Epoch 84/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.6970 - accuracy: 0.7467 - val_loss: 1.5144 - val_accuracy: 0.5750\n",
      "Epoch 85/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.7217 - accuracy: 0.7394 - val_loss: 1.1672 - val_accuracy: 0.6395\n",
      "Epoch 86/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6968 - accuracy: 0.7564 - val_loss: 1.2437 - val_accuracy: 0.6433\n",
      "Epoch 87/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.6815 - accuracy: 0.7665 - val_loss: 1.9363 - val_accuracy: 0.4573\n",
      "Epoch 88/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.7020 - accuracy: 0.7560 - val_loss: 1.4027 - val_accuracy: 0.5294\n",
      "Epoch 89/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.6679 - accuracy: 0.7685 - val_loss: 1.9518 - val_accuracy: 0.4269\n",
      "Epoch 90/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.6635 - accuracy: 0.7624 - val_loss: 1.1280 - val_accuracy: 0.6319\n",
      "Epoch 91/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6468 - accuracy: 0.7770 - val_loss: 1.5254 - val_accuracy: 0.5579\n",
      "Epoch 92/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6436 - accuracy: 0.7806 - val_loss: 1.5640 - val_accuracy: 0.5427\n",
      "Epoch 93/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.6140 - accuracy: 0.7879 - val_loss: 2.0630 - val_accuracy: 0.4516\n",
      "Epoch 94/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.6713 - accuracy: 0.7669 - val_loss: 1.7660 - val_accuracy: 0.5294\n",
      "Epoch 95/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6211 - accuracy: 0.7782 - val_loss: 2.0364 - val_accuracy: 0.4478\n",
      "Epoch 96/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6345 - accuracy: 0.7875 - val_loss: 1.3917 - val_accuracy: 0.5882\n",
      "Epoch 97/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.6318 - accuracy: 0.7855 - val_loss: 1.7534 - val_accuracy: 0.5237\n",
      "Epoch 98/250\n",
      "78/78 [==============================] - 12s 152ms/step - loss: 0.6181 - accuracy: 0.7846 - val_loss: 3.4954 - val_accuracy: 0.3757\n",
      "Epoch 99/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.6516 - accuracy: 0.7758 - val_loss: 1.6373 - val_accuracy: 0.5009\n",
      "Epoch 100/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.5563 - accuracy: 0.8024 - val_loss: 1.2160 - val_accuracy: 0.5901\n",
      "Epoch 101/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6005 - accuracy: 0.7988 - val_loss: 1.8111 - val_accuracy: 0.5085\n",
      "Epoch 102/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.6350 - accuracy: 0.7733 - val_loss: 1.2385 - val_accuracy: 0.5636\n",
      "Epoch 103/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.5865 - accuracy: 0.7895 - val_loss: 3.5222 - val_accuracy: 0.3435\n",
      "Epoch 104/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.5786 - accuracy: 0.7984 - val_loss: 1.5635 - val_accuracy: 0.5996\n",
      "Epoch 105/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.6016 - accuracy: 0.7911 - val_loss: 1.2477 - val_accuracy: 0.6281\n",
      "Epoch 106/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.5760 - accuracy: 0.7943 - val_loss: 1.3754 - val_accuracy: 0.6091\n",
      "Epoch 107/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.5916 - accuracy: 0.7964 - val_loss: 0.7620 - val_accuracy: 0.7400\n",
      "Epoch 108/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.5881 - accuracy: 0.7859 - val_loss: 2.1791 - val_accuracy: 0.4668\n",
      "Epoch 109/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.5938 - accuracy: 0.7919 - val_loss: 1.2558 - val_accuracy: 0.5882\n",
      "Epoch 110/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.5940 - accuracy: 0.7907 - val_loss: 2.4102 - val_accuracy: 0.4592\n",
      "Epoch 111/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.5652 - accuracy: 0.7972 - val_loss: 2.1317 - val_accuracy: 0.4573\n",
      "Epoch 112/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.5417 - accuracy: 0.8101 - val_loss: 1.7558 - val_accuracy: 0.5218\n",
      "Epoch 113/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.5355 - accuracy: 0.8158 - val_loss: 2.6013 - val_accuracy: 0.4573\n",
      "Epoch 114/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.5333 - accuracy: 0.8109 - val_loss: 2.2140 - val_accuracy: 0.4915\n",
      "Epoch 115/250\n",
      "78/78 [==============================] - 12s 152ms/step - loss: 0.5895 - accuracy: 0.7923 - val_loss: 2.2887 - val_accuracy: 0.4782\n",
      "Epoch 116/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.5500 - accuracy: 0.8077 - val_loss: 1.5164 - val_accuracy: 0.5977\n",
      "Epoch 117/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.5076 - accuracy: 0.8275 - val_loss: 1.8115 - val_accuracy: 0.4554\n",
      "Epoch 118/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.5351 - accuracy: 0.8121 - val_loss: 2.8035 - val_accuracy: 0.4023\n",
      "Epoch 119/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4922 - accuracy: 0.8230 - val_loss: 1.6445 - val_accuracy: 0.5787\n",
      "Epoch 120/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.5509 - accuracy: 0.8089 - val_loss: 2.1051 - val_accuracy: 0.4820\n",
      "Epoch 121/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.5783 - accuracy: 0.8040 - val_loss: 2.2662 - val_accuracy: 0.4915\n",
      "Epoch 122/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.5206 - accuracy: 0.8190 - val_loss: 0.9632 - val_accuracy: 0.7116\n",
      "Epoch 123/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.5099 - accuracy: 0.8246 - val_loss: 1.5825 - val_accuracy: 0.5750\n",
      "Epoch 124/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4997 - accuracy: 0.8263 - val_loss: 1.3009 - val_accuracy: 0.5996\n",
      "Epoch 125/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4933 - accuracy: 0.8315 - val_loss: 1.0551 - val_accuracy: 0.6528\n",
      "Epoch 126/250\n",
      "78/78 [==============================] - 11s 139ms/step - loss: 0.5133 - accuracy: 0.8133 - val_loss: 2.1299 - val_accuracy: 0.4896\n",
      "Epoch 127/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.5175 - accuracy: 0.8129 - val_loss: 1.4455 - val_accuracy: 0.5863\n",
      "Epoch 128/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.4934 - accuracy: 0.8283 - val_loss: 4.0259 - val_accuracy: 0.4042\n",
      "Epoch 129/250\n",
      "78/78 [==============================] - 11s 139ms/step - loss: 0.4689 - accuracy: 0.8388 - val_loss: 1.0707 - val_accuracy: 0.6509\n",
      "Epoch 130/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4907 - accuracy: 0.8287 - val_loss: 1.0719 - val_accuracy: 0.6357\n",
      "Epoch 131/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.4841 - accuracy: 0.8307 - val_loss: 1.4660 - val_accuracy: 0.6224\n",
      "Epoch 132/250\n",
      "78/78 [==============================] - 12s 153ms/step - loss: 0.4781 - accuracy: 0.8263 - val_loss: 0.9961 - val_accuracy: 0.6964\n",
      "Epoch 133/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4850 - accuracy: 0.8400 - val_loss: 1.8412 - val_accuracy: 0.5351\n",
      "Epoch 134/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4703 - accuracy: 0.8372 - val_loss: 1.1089 - val_accuracy: 0.6490\n",
      "Epoch 135/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4836 - accuracy: 0.8291 - val_loss: 2.8753 - val_accuracy: 0.4421\n",
      "Epoch 136/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4561 - accuracy: 0.8364 - val_loss: 2.2992 - val_accuracy: 0.4288\n",
      "Epoch 137/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4604 - accuracy: 0.8424 - val_loss: 1.5429 - val_accuracy: 0.5484\n",
      "Epoch 138/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4772 - accuracy: 0.8259 - val_loss: 3.1918 - val_accuracy: 0.4137\n",
      "Epoch 139/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4489 - accuracy: 0.8481 - val_loss: 4.0981 - val_accuracy: 0.3548\n",
      "Epoch 140/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4904 - accuracy: 0.8275 - val_loss: 2.5181 - val_accuracy: 0.4554\n",
      "Epoch 141/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4608 - accuracy: 0.8444 - val_loss: 0.9267 - val_accuracy: 0.7230\n",
      "Epoch 142/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4419 - accuracy: 0.8489 - val_loss: 2.9485 - val_accuracy: 0.3928\n",
      "Epoch 143/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4597 - accuracy: 0.8380 - val_loss: 1.2829 - val_accuracy: 0.6262\n",
      "Epoch 144/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4862 - accuracy: 0.8275 - val_loss: 0.9111 - val_accuracy: 0.7097\n",
      "Epoch 145/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4427 - accuracy: 0.8436 - val_loss: 1.8500 - val_accuracy: 0.5180\n",
      "Epoch 146/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4231 - accuracy: 0.8473 - val_loss: 1.3410 - val_accuracy: 0.6300\n",
      "Epoch 147/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4295 - accuracy: 0.8465 - val_loss: 1.3642 - val_accuracy: 0.5920\n",
      "Epoch 148/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.4193 - accuracy: 0.8473 - val_loss: 1.4286 - val_accuracy: 0.6319\n",
      "Epoch 149/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4268 - accuracy: 0.8448 - val_loss: 1.4308 - val_accuracy: 0.6091\n",
      "Epoch 150/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4267 - accuracy: 0.8549 - val_loss: 1.7839 - val_accuracy: 0.5313\n",
      "Epoch 151/250\n",
      "78/78 [==============================] - 12s 151ms/step - loss: 0.4170 - accuracy: 0.8489 - val_loss: 1.3127 - val_accuracy: 0.6471\n",
      "Epoch 152/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4099 - accuracy: 0.8562 - val_loss: 1.3972 - val_accuracy: 0.6224\n",
      "Epoch 153/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3921 - accuracy: 0.8691 - val_loss: 2.1823 - val_accuracy: 0.4687\n",
      "Epoch 154/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.4213 - accuracy: 0.8578 - val_loss: 0.9783 - val_accuracy: 0.7135\n",
      "Epoch 155/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3957 - accuracy: 0.8594 - val_loss: 1.1869 - val_accuracy: 0.6641\n",
      "Epoch 156/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4012 - accuracy: 0.8533 - val_loss: 2.6976 - val_accuracy: 0.3890\n",
      "Epoch 157/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.4126 - accuracy: 0.8525 - val_loss: 1.2944 - val_accuracy: 0.6509\n",
      "Epoch 158/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3867 - accuracy: 0.8675 - val_loss: 1.7474 - val_accuracy: 0.5712\n",
      "Epoch 159/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4071 - accuracy: 0.8554 - val_loss: 1.2627 - val_accuracy: 0.6698\n",
      "Epoch 160/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4027 - accuracy: 0.8549 - val_loss: 1.7943 - val_accuracy: 0.5484\n",
      "Epoch 161/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3742 - accuracy: 0.8735 - val_loss: 1.3723 - val_accuracy: 0.5920\n",
      "Epoch 162/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3849 - accuracy: 0.8671 - val_loss: 0.9638 - val_accuracy: 0.7116\n",
      "Epoch 163/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3800 - accuracy: 0.8630 - val_loss: 1.2935 - val_accuracy: 0.6660\n",
      "Epoch 164/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3786 - accuracy: 0.8610 - val_loss: 1.2044 - val_accuracy: 0.6850\n",
      "Epoch 165/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.4198 - accuracy: 0.8533 - val_loss: 1.4126 - val_accuracy: 0.6414\n",
      "Epoch 166/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.4091 - accuracy: 0.8566 - val_loss: 2.6322 - val_accuracy: 0.4535\n",
      "Epoch 167/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3821 - accuracy: 0.8683 - val_loss: 4.7884 - val_accuracy: 0.3491\n",
      "Epoch 168/250\n",
      "78/78 [==============================] - 12s 151ms/step - loss: 0.3621 - accuracy: 0.8711 - val_loss: 1.1150 - val_accuracy: 0.6869\n",
      "Epoch 169/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3804 - accuracy: 0.8711 - val_loss: 1.2727 - val_accuracy: 0.6584\n",
      "Epoch 170/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3674 - accuracy: 0.8707 - val_loss: 0.9336 - val_accuracy: 0.7306\n",
      "Epoch 171/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3548 - accuracy: 0.8671 - val_loss: 3.3967 - val_accuracy: 0.3947\n",
      "Epoch 172/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3396 - accuracy: 0.8857 - val_loss: 0.8937 - val_accuracy: 0.7476\n",
      "Epoch 173/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3713 - accuracy: 0.8642 - val_loss: 1.2170 - val_accuracy: 0.6490\n",
      "Epoch 174/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3703 - accuracy: 0.8711 - val_loss: 1.4593 - val_accuracy: 0.6565\n",
      "Epoch 175/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3703 - accuracy: 0.8727 - val_loss: 1.2370 - val_accuracy: 0.6509\n",
      "Epoch 176/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3577 - accuracy: 0.8699 - val_loss: 1.1897 - val_accuracy: 0.6774\n",
      "Epoch 177/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3368 - accuracy: 0.8840 - val_loss: 2.4504 - val_accuracy: 0.4554\n",
      "Epoch 178/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3704 - accuracy: 0.8747 - val_loss: 1.0340 - val_accuracy: 0.6926\n",
      "Epoch 179/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3215 - accuracy: 0.8865 - val_loss: 3.7799 - val_accuracy: 0.3871\n",
      "Epoch 180/250\n",
      "78/78 [==============================] - 11s 139ms/step - loss: 0.3547 - accuracy: 0.8788 - val_loss: 1.0267 - val_accuracy: 0.7324\n",
      "Epoch 181/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3507 - accuracy: 0.8760 - val_loss: 2.1804 - val_accuracy: 0.4858\n",
      "Epoch 182/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3522 - accuracy: 0.8808 - val_loss: 2.0849 - val_accuracy: 0.5408\n",
      "Epoch 183/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3263 - accuracy: 0.8796 - val_loss: 1.2313 - val_accuracy: 0.6736\n",
      "Epoch 184/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3303 - accuracy: 0.8861 - val_loss: 1.2434 - val_accuracy: 0.6717\n",
      "Epoch 185/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3270 - accuracy: 0.8776 - val_loss: 1.8422 - val_accuracy: 0.5484\n",
      "Epoch 186/250\n",
      "78/78 [==============================] - 12s 153ms/step - loss: 0.3408 - accuracy: 0.8792 - val_loss: 1.1892 - val_accuracy: 0.6528\n",
      "Epoch 187/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3142 - accuracy: 0.8941 - val_loss: 1.5857 - val_accuracy: 0.6490\n",
      "Epoch 188/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3143 - accuracy: 0.8836 - val_loss: 1.9628 - val_accuracy: 0.5806\n",
      "Epoch 189/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3199 - accuracy: 0.8848 - val_loss: 1.4389 - val_accuracy: 0.6357\n",
      "Epoch 190/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3600 - accuracy: 0.8743 - val_loss: 1.8645 - val_accuracy: 0.5560\n",
      "Epoch 191/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3214 - accuracy: 0.8905 - val_loss: 1.0682 - val_accuracy: 0.7097\n",
      "Epoch 192/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.2730 - accuracy: 0.9026 - val_loss: 1.3359 - val_accuracy: 0.6452\n",
      "Epoch 193/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2977 - accuracy: 0.8994 - val_loss: 0.7833 - val_accuracy: 0.7495\n",
      "Epoch 194/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3425 - accuracy: 0.8816 - val_loss: 1.2415 - val_accuracy: 0.6584\n",
      "Epoch 195/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3093 - accuracy: 0.8832 - val_loss: 1.7802 - val_accuracy: 0.5617\n",
      "Epoch 196/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3159 - accuracy: 0.8820 - val_loss: 1.3578 - val_accuracy: 0.6167\n",
      "Epoch 197/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3150 - accuracy: 0.8853 - val_loss: 1.2118 - val_accuracy: 0.6603\n",
      "Epoch 198/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3085 - accuracy: 0.8905 - val_loss: 2.0664 - val_accuracy: 0.5863\n",
      "Epoch 199/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3120 - accuracy: 0.8913 - val_loss: 1.2112 - val_accuracy: 0.6888\n",
      "Epoch 200/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3223 - accuracy: 0.8808 - val_loss: 1.3260 - val_accuracy: 0.6584\n",
      "Epoch 201/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3245 - accuracy: 0.8861 - val_loss: 2.6293 - val_accuracy: 0.5218\n",
      "Epoch 202/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3402 - accuracy: 0.8804 - val_loss: 1.4284 - val_accuracy: 0.6300\n",
      "Epoch 203/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2990 - accuracy: 0.8909 - val_loss: 1.6776 - val_accuracy: 0.5598\n",
      "Epoch 204/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.2793 - accuracy: 0.9063 - val_loss: 0.9348 - val_accuracy: 0.7268\n",
      "Epoch 205/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.3158 - accuracy: 0.8897 - val_loss: 1.1869 - val_accuracy: 0.6641\n",
      "Epoch 206/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2814 - accuracy: 0.8954 - val_loss: 1.5461 - val_accuracy: 0.6546\n",
      "Epoch 207/250\n",
      "78/78 [==============================] - 11s 140ms/step - loss: 0.3166 - accuracy: 0.8848 - val_loss: 1.4407 - val_accuracy: 0.6528\n",
      "Epoch 208/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.2851 - accuracy: 0.9010 - val_loss: 1.3471 - val_accuracy: 0.6793\n",
      "Epoch 209/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2799 - accuracy: 0.9051 - val_loss: 1.4807 - val_accuracy: 0.7059\n",
      "Epoch 210/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2956 - accuracy: 0.9051 - val_loss: 1.0955 - val_accuracy: 0.7135\n",
      "Epoch 211/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.2806 - accuracy: 0.8966 - val_loss: 1.4100 - val_accuracy: 0.6433\n",
      "Epoch 212/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.3146 - accuracy: 0.8913 - val_loss: 1.3733 - val_accuracy: 0.6603\n",
      "Epoch 213/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3031 - accuracy: 0.8865 - val_loss: 2.2158 - val_accuracy: 0.5579\n",
      "Epoch 214/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2844 - accuracy: 0.9002 - val_loss: 1.5390 - val_accuracy: 0.5882\n",
      "Epoch 215/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2631 - accuracy: 0.9038 - val_loss: 4.4193 - val_accuracy: 0.3226\n",
      "Epoch 216/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.3306 - accuracy: 0.8836 - val_loss: 0.8242 - val_accuracy: 0.7552\n",
      "Epoch 217/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2774 - accuracy: 0.9026 - val_loss: 2.8633 - val_accuracy: 0.4137\n",
      "Epoch 218/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2902 - accuracy: 0.9002 - val_loss: 1.8719 - val_accuracy: 0.6091\n",
      "Epoch 219/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2781 - accuracy: 0.9010 - val_loss: 1.8517 - val_accuracy: 0.5712\n",
      "Epoch 220/250\n",
      "78/78 [==============================] - 12s 152ms/step - loss: 0.2640 - accuracy: 0.9046 - val_loss: 1.8826 - val_accuracy: 0.5825\n",
      "Epoch 221/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2750 - accuracy: 0.9042 - val_loss: 1.6167 - val_accuracy: 0.6357\n",
      "Epoch 222/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.2656 - accuracy: 0.9091 - val_loss: 1.7348 - val_accuracy: 0.5806\n",
      "Epoch 223/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.3141 - accuracy: 0.8929 - val_loss: 2.0578 - val_accuracy: 0.5825\n",
      "Epoch 224/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2372 - accuracy: 0.9168 - val_loss: 1.5353 - val_accuracy: 0.6053\n",
      "Epoch 225/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.2902 - accuracy: 0.9034 - val_loss: 2.0291 - val_accuracy: 0.5427\n",
      "Epoch 226/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2603 - accuracy: 0.9091 - val_loss: 1.7218 - val_accuracy: 0.6186\n",
      "Epoch 227/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2801 - accuracy: 0.9063 - val_loss: 1.0503 - val_accuracy: 0.7324\n",
      "Epoch 228/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.2873 - accuracy: 0.8982 - val_loss: 1.3333 - val_accuracy: 0.6812\n",
      "Epoch 229/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.2748 - accuracy: 0.9051 - val_loss: 1.7173 - val_accuracy: 0.6091\n",
      "Epoch 230/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2603 - accuracy: 0.9087 - val_loss: 2.2569 - val_accuracy: 0.5484\n",
      "Epoch 231/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2370 - accuracy: 0.9152 - val_loss: 1.2763 - val_accuracy: 0.6698\n",
      "Epoch 232/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2696 - accuracy: 0.9042 - val_loss: 2.1966 - val_accuracy: 0.5351\n",
      "Epoch 233/250\n",
      "78/78 [==============================] - 11s 138ms/step - loss: 0.2790 - accuracy: 0.9006 - val_loss: 1.4637 - val_accuracy: 0.6717\n",
      "Epoch 234/250\n",
      "78/78 [==============================] - 11s 134ms/step - loss: 0.2356 - accuracy: 0.9139 - val_loss: 1.9825 - val_accuracy: 0.5901\n",
      "Epoch 235/250\n",
      "78/78 [==============================] - 12s 150ms/step - loss: 0.2708 - accuracy: 0.9026 - val_loss: 2.3427 - val_accuracy: 0.5408\n",
      "Epoch 236/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2618 - accuracy: 0.9067 - val_loss: 1.2308 - val_accuracy: 0.6793\n",
      "Epoch 237/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.2436 - accuracy: 0.9160 - val_loss: 1.2005 - val_accuracy: 0.6983\n",
      "Epoch 238/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2606 - accuracy: 0.9067 - val_loss: 1.3374 - val_accuracy: 0.6433\n",
      "Epoch 239/250\n",
      "78/78 [==============================] - 10s 134ms/step - loss: 0.2470 - accuracy: 0.9099 - val_loss: 0.7983 - val_accuracy: 0.7856\n",
      "Epoch 240/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2452 - accuracy: 0.9139 - val_loss: 1.9914 - val_accuracy: 0.5693\n",
      "Epoch 241/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2264 - accuracy: 0.9224 - val_loss: 0.8074 - val_accuracy: 0.7514\n",
      "Epoch 242/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2218 - accuracy: 0.9147 - val_loss: 1.4116 - val_accuracy: 0.6907\n",
      "Epoch 243/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2291 - accuracy: 0.9184 - val_loss: 1.3721 - val_accuracy: 0.6755\n",
      "Epoch 244/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2568 - accuracy: 0.9123 - val_loss: 1.0822 - val_accuracy: 0.7268\n",
      "Epoch 245/250\n",
      "78/78 [==============================] - 11s 138ms/step - loss: 0.2707 - accuracy: 0.9042 - val_loss: 2.0198 - val_accuracy: 0.5503\n",
      "Epoch 246/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2105 - accuracy: 0.9257 - val_loss: 0.9126 - val_accuracy: 0.7552\n",
      "Epoch 247/250\n",
      "78/78 [==============================] - 11s 137ms/step - loss: 0.2641 - accuracy: 0.9071 - val_loss: 2.1017 - val_accuracy: 0.5693\n",
      "Epoch 248/250\n",
      "78/78 [==============================] - 11s 136ms/step - loss: 0.2549 - accuracy: 0.9067 - val_loss: 1.5180 - val_accuracy: 0.6262\n",
      "Epoch 249/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2313 - accuracy: 0.9160 - val_loss: 2.3919 - val_accuracy: 0.5123\n",
      "Epoch 250/250\n",
      "78/78 [==============================] - 11s 135ms/step - loss: 0.2169 - accuracy: 0.9228 - val_loss: 1.1392 - val_accuracy: 0.7116\n"
     ]
    }
   ],
   "source": [
    "#@title Training of ResNet-50\n",
    "epochs = 200\n",
    "resnet_callbacks, model_folder_dir = create_folders_and_callbacks(model_name='ResNet50_From_Scratch_CB')\n",
    "\n",
    "train_gen, val_gen, test_gen = get_dataset_generator(dir)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_gen,\n",
    "    callbacks = resnet_callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA1PZYFxSyDO"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Save of models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5UfFNLhS4g6"
   },
   "outputs": [],
   "source": [
    "model.save(\"saved_models/...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NSKgzvoLBQT"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Loading of models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltJzWhgvuYSw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fc1a5882-54c7-4b12-97ab-08eaa2fdbd57"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f1f74d874d0>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#@title **Loading of an existing model (having only the weights)**\n",
    "# after having already built the model...\n",
    "tl_model.load_weights('saved_models/...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EMAei7BR-te"
   },
   "outputs": [],
   "source": [
    "#@title **Loading of an existing model (Complete)**\n",
    "model = tf.keras.models.load_model(\"saved_models/...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWQhfwtmSShW"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**Model testing**\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_test_metrics = model.evaluate(test_gen, return_dict=True)"
   ],
   "metadata": {
    "id": "vMsZ52Gk9cPe",
    "outputId": "f25b1519-d956-4cc2-d32c-3651c43125d9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1669559313444,
     "user_tz": -60,
     "elapsed": 419,
     "user": {
      "displayName": "Andrea Cerasani",
      "userId": "02098686880230063779"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17/17 [==============================] - 1s 59ms/step - loss: 0.8071 - accuracy: 0.7396\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_Slc1rrspXF"
   },
   "outputs": [],
   "source": [
    "#@title **Testing a model and re-saving**\n",
    "\n",
    "train_gen, val_gen, test_gen = get_dataset_generator(dir)\n",
    "\n",
    "# saving model in saved_models/modelname_accuracy\n",
    "saved_model_name = 'ResNet50_from_scratch_' + str(model_test_metrics[\"accuracy\"])\n",
    "saved_model_dir = 'saved_models/' + saved_model_name\n",
    "ft_model.save(saved_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUHrx4B3SYko"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**Download of the model in .zip format**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO7CjPfa_gSJ"
   },
   "outputs": [],
   "source": [
    "zipped_model = saved_model_dir + '/' + saved_model_name + '.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwoOlqg7_vAT"
   },
   "outputs": [],
   "source": [
    "!zip -r {zipped_model} {saved_model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uuP0QlFQ_zSm",
    "outputId": "15adb4b9-8097-4c41-f88a-eb3d488d9e4a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_1eacb861-ce38-448f-9c4d-517fc07e5c27\", \"convNeXtXLarge10.914814829826355.zip\", 3924520050)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(zipped_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mckeoLzeOAvx"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}